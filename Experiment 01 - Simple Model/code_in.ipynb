{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import Sequence\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python.client import device_lib\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.models import model_from_json\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline\n",
    "\n",
    "import glob\n",
    "import imageio\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "from datetime import timezone, datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize\n",
    "\n",
    "## Define constant variable\n",
    "- data_dir : root directory for date\n",
    "- label_file : location of label file\n",
    "- history_csv : location of history output file\n",
    "- model_file : location of model output file\n",
    "- weight_file : locaiton of weight output file\n",
    "\n",
    "## Checking processor\n",
    "Checking CPU and GPU available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# input\n",
    "data_dir = '../../DATASET/Black/data/'\n",
    "label_file = '../../DATASET/Black/label.csv'\n",
    "\n",
    "# output\n",
    "timestamp = int(datetime.now().timestamp()*1000)\n",
    "history_csv = './results/history_{}.csv'.format(timestamp)\n",
    "confusion_csv = './results/confusion_{}.csv'.format(timestamp)\n",
    "model_file = './models/model_{}.json'.format(timestamp)\n",
    "weight_file = './models/weight_{}.h5'.format(timestamp)\n",
    "log_tb = './logs/tensorboard/{}/'.format(timestamp)\n",
    "\n",
    "# config training\n",
    "batch_size = 2\n",
    "num_epochs = 10\n",
    "learning_rate = 0.0005\n",
    "\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Model\n",
    "create simple model for CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model() :\n",
    "    model = Sequential()\n",
    "\n",
    "    # Convolution\n",
    "    ## 5x5 convolution with 2x2 stride and 32 filters\n",
    "    model.add(Conv2D(32, (5, 5), strides = (4, 4), padding='same',\n",
    "                     input_shape=(3000, 3000, 1)))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    ## 2x2 max pooling reduces to 3 x 3 x 32\n",
    "    model.add(MaxPooling2D(pool_size=(4, 4)))\n",
    "\n",
    "    ## Another 5x5 convolution with 2x2 stride and 32 filters\n",
    "    model.add(Conv2D(32, (5, 5), strides = (4, 4)))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    ## 2x2 max pooling reduces to 3 x 3 x 32\n",
    "    model.add(MaxPooling2D(pool_size=(4, 4)))\n",
    "\n",
    "    ## Flatten turns 3x3x32 into 288x1\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(100))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Dense(100))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Dense(2))\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data\n",
    "## Prepare label and input file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df  = pd.read_csv(label_file, index_col=0)\n",
    "df.image = data_dir + df.image\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data set\n",
    "split data to train(70%), val(15%) and test(15%) set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split - train:70, val:15, test:15\n",
    "x_train, x_test, y_train, y_test = train_test_split(df.image, df.label, test_size=0.30)\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=0.50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create data generator\n",
    "create data generator for query data from data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(Sequence) :\n",
    "    def __init__(self, x, y, batch_size) :\n",
    "        self.x = x\n",
    "        self.y = keras.utils.to_categorical(y, 2)\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def __len__(self) :\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "    \n",
    "    def __getitem__(self, idx) :\n",
    "        # get all data in batch number idx\n",
    "        start = idx * self.batch_size\n",
    "        end = (idx+1) * self.batch_size\n",
    "        names = self.x.iloc[start : end]\n",
    "        \n",
    "        batch_x = np.array([ np.array(imageio.imread(f, pilmode='L')).reshape((3000, 3000, 1)) for f in names])\n",
    "        batch_x = batch_x.astype('float16')\n",
    "        batch_x /= 255\n",
    "        batch_y = np.array(self.y[start: end])\n",
    "        return batch_x, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = DataGenerator(x_train, y_train, batch_size)\n",
    "val_generator = DataGenerator(x_val, y_val, batch_size)\n",
    "test_generator = DataGenerator(x_test, y_test, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training model\n",
    "traing model with training set and validate set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizers.rmsprop(lr=learning_rate, decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=log_tb)\n",
    "\n",
    "history = model.fit_generator(generator=train_generator,\n",
    "                                          steps_per_epoch=(len(train_generator) // batch_size),\n",
    "                                          epochs=num_epochs,\n",
    "                                          verbose=1,\n",
    "                                          validation_data=val_generator,\n",
    "                                          validation_steps=(len(val_generator) // batch_size),\n",
    "                                          callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot loss and acc graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_accuracy(history):\n",
    "    fig = plt.figure(figsize=(12, 6))\n",
    "    ax = fig.add_subplot(1, 2, 1)\n",
    "    ax.plot(history.history[\"loss\"],'r-x', label=\"Train Loss\")\n",
    "    ax.plot(history.history[\"val_loss\"],'b-x', label=\"Validation Loss\")\n",
    "    ax.legend()\n",
    "    ax.set_title('cross_entropy loss')\n",
    "    ax.grid(True)\n",
    "\n",
    "\n",
    "    ax = fig.add_subplot(1, 2, 2)\n",
    "    ax.plot(history.history[\"acc\"],'r-x', label=\"Train Accuracy\")\n",
    "    ax.plot(history.history[\"val_acc\"],'b-x', label=\"Validation Accuracy\")\n",
    "    ax.legend()\n",
    "    ax.set_title('accuracy')\n",
    "    ax.grid(True)\n",
    "    \n",
    "\n",
    "plot_loss_accuracy(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model\n",
    "- save model to .json file\n",
    "- save weight to .h5 file\n",
    "- save history to .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(model_file, \"w+\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights(weight_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df = pd.DataFrame(history.history)\n",
    "history_df.to_csv(history_csv)\n",
    "history_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eavalute\n",
    "## predict Y\n",
    "predict Y with test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "_y_pred = model.predict_generator(test_generator, verbose=1)\n",
    "y_pred = _y_pred.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion matrix\n",
    "calculate confusion matrix and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.concat([y_test.reset_index(), pd.Series(y_pred, name='predict')], axis=1)\n",
    "false_positive_df = result_df[(result_df.predict - result_df.label) == 1]\n",
    "false_negative_df = result_df[(result_df.predict - result_df.label) == -1]\n",
    "true_positive_df = result_df[((result_df.predict - result_df.label) == 0) & (result_df.label == 1)]\n",
    "true_negative_df = result_df[((result_df.predict - result_df.label) == 0) & (result_df.label == 0)]\n",
    "\n",
    "fp = len(false_positive_df)\n",
    "fn = len(false_negative_df)\n",
    "tp = len(true_positive_df)\n",
    "tn = len(true_negative_df)\n",
    "tr = tp+tn\n",
    "fp_percent = fp / len(result_df)\n",
    "fn_percent = fn / len(result_df)\n",
    "tp_percent = tp / len(result_df)\n",
    "tn_percent = tn / len(result_df)\n",
    "tr_percent = tr / len(result_df)\n",
    "total = len(result_df)\n",
    "\n",
    "confusion_mat = pd.DataFrame({'false_positive': [fp, fp_percent],\n",
    "                                              'false_negative': [fn, fn_percent],\n",
    "                                              'true_positive': [tp, tp_percent],\n",
    "                                              'true_negative': [tn, tn_percent],\n",
    "                                              'true_result':[tr, tr_percent],\n",
    "                                              'total': [total, 1.0]}, index=['amount', 'percent'])\n",
    "confusion_mat.to_csv(confusion_csv)\n",
    "confusion_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load json and create model\n",
    "\n",
    "# json_file = open(model_file, 'r')\n",
    "# loaded_model_json = json_file.read()\n",
    "# json_file.close()\n",
    "# loaded_model = model_from_json(loaded_model_json)\n",
    "# # load weights into new model\n",
    "# loaded_model.load_weights(weight_file)\n",
    "# print(\"Loaded model from disk\")\n",
    "\n",
    "# opt = keras.optimizers.rmsprop(lr=0.0005, decay=1e-6)\n",
    "# loaded_model.compile(loss='categorical_crossentropy',\n",
    "#               optimizer=opt,\n",
    "#               metrics=['accuracy'])\n",
    "# result = loaded_model.evaluate_generator(test_generator, verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
